---
title: "Google Data Analytics Capstone | Case Study 2"
author: "Alexandra Androutsopoulou"
date: "7/11/2021"
output: html_document
---

## How Can a Wellness Technology Company Play It Smart?

![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQG8UpKLaHfpdfO96tXSbJMtBKnfkIzJqmWOw&usqp=CAU)

##### This is my version of the capstone project from the Google Data Analytics Course. It follows the 6 steps of the data analysis process to ensure its completion: Ask, Prepare, Process, Analyze, Share, & Act.


### **STEP 1: ASK**

##### **1.1 BUSINESS TASK**

##### **Analyze FitBit fitness tracker data to gain insights into how customers are using the app, and identify trends and opportunities for Bellabeat's growth marketing strategy.**
 

##### **1.2 BUSINESS OBJECTIVES**

###### * What are the trends in smart device usage?
###### * How could these trends apply to Bellabeat customers?
###### * How could these trends help influence Bellabeat marketing strategy?


##### **1.3 KEY STAKEHOLDERS**

###### **Executive team**
###### * Urška Sršen | Bellabeat’s cofounder and Chief Creative Officer
###### * Sando Mur | Mathematician and Bellabeat’s cofounder 
###### **Data Science team**
###### * Bellabeat marketing analytics team


##### **1.4 DELIVERABLES**

###### * A clear summary of the business task
###### * A description of all data sources used
###### * Documentation of any cleaning or manipulation of data
###### * A summary of the analysis
###### * Supporting visualizations and key findings
###### * High-level content recommendations based on the analysis


### **STEP 2: PREPARE**

##### **2.1 INFO ON THE DATASET**
###### * The data set is publicly available on Kaggle [FitBit Fitness Tracker Data](https://www.kaggle.com/arashnic/fitbit) 
###### * Stored in 18 csv files, in wide format.
###### * Generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016.
###### * 30 eligible Fitbit users consented to the submission of personal tracker data.
###### * Data collected includes physical activity (min), heart rate, sleep monitoring, daily activity and steps.

##### **2.2 LIMITATIONS OF DATASET**

###### * Data is collected 6 years ago in 2016. Users’ daily activity, fitness and sleeping habits, diet and food consumption may have changed since then. Data may not be timely or relevant.
###### * Sample size of 30 FitBit users is not representative of the entire fitness population.
###### * As data is collected in a survey, we are unable to ascertain its integrity or accuracy.


##### **2.3 DOES MY DATA ROCCC?**

###### *ROCCC stands for Reliable, Original, Comprehensive, Current, and Cited data*
###### * Reliable — LOW — Not reliable as it only has 30 respondents
###### * Original — LOW — Third party provider (Amazon Mechanical Turk)
###### * Comprehensive — MED — Parameters match most of Bellabeat products’ parameters
###### * Current — LOW — Data is 6 years old and may not be relevant
###### * Cited — LOW — Unknown, as data collected from third party

###### **Overall, the dataset is considered bad quality data and it is not recommended to produce business recommendations based on this data.**


### **STEP 3: PROCESS**

##### **3.1 TOOLS**

###### I am using **R** for Data Cleaning, Transformation, Analysis and Visualisation.

##### **3.2 SETTING UP MY ENVIRONMENT**

```{r}
library(tidyverse)
library(lubridate)
library(dplyr)
library(ggplot2)
library(readr)
library(here)
library(janitor)
library(skimr)
```
##### **3.3 IMPORTING DATA SET**

#### **I. Daily Activity**
```{r}
library(readr)
daily_activity <- read_csv("E:/8.Capstone Case Study 2_Bellabeat/Fitabase Data 4.12.16-5.12.16/dailyActivity_merged.csv")
```
#### **II. Daily Calories**
```{r}
daily_calories <- read_csv("E:/8.Capstone Case Study 2_Bellabeat/Fitabase Data 4.12.16-5.12.16/dailyCalories_merged.csv")
```

#### **III. Daily Intensities**
```{r}
daily_intensities <- read_csv("E:/8.Capstone Case Study 2_Bellabeat/Fitabase Data 4.12.16-5.12.16/dailyIntensities_merged.csv")
```
#### **IV. Daily Sleep**

```{r}
daily_sleep <- read_csv("E:/8.Capstone Case Study 2_Bellabeat/Fitabase Data 4.12.16-5.12.16/sleepDay_merged.csv")
```

#### **V. Weight Info**
```{r}
weight_info <- read_csv("E:/8.Capstone Case Study 2_Bellabeat/Fitabase Data 4.12.16-5.12.16/weightLogInfo_merged.csv")
```
#### **VI.Heartrate Info**
```{r}
heartrate_info <- read_csv("E:/8.Capstone Case Study 2_Bellabeat/Fitabase Data 4.12.16-5.12.16/heartrate_seconds_merged.csv")
```
##### **3.4 DATA CLEANING**
#### **I. Daily Activity**

###### **PREVIEWING THE FIRST 10 ROWS TO FAMILIARIZE WITH DATA**

```{r}
head(daily_activity)
```

###### **FINDING OUT BASIC INFORMATION ABOUT THE DATA**

###### * **Name of the dataset, Number of rows & columns, Data types**

```{r}
library (skimr)
skim_without_charts (daily_activity)
```


###### * **Column Names**

```{r}
colnames(daily_activity)
```

###### **CHECKING FOR NULL/MISSING AND DUBLICATE VALUES IN THE DATA**

```{r}
sum(is.na(daily_activity))
sum(duplicated(daily_activity))
```
###### **COUNTING UNIQUE IDs TO CONFIRM WHETHER DATA HAS 30 IDs AS CLAIMED BY THE SURVEY**

```{r}
library(dplyr)
daily_activity %>%
 summarize(unique_Ids = n_distinct(Id))
```

###### **Overall observations**
###### 1. There aren't Null or missing or duplicate values
###### 2. Data has 15 columns and 940 rows
###### 3. ActivityDate is wrongly classified as character datatype and has to be converted to datetime64 datatype.
###### 4. There are 33 unique IDs, instead of 30 unique IDs as expected.

#### **II. Daily Calories**
###### **PREVIEWING THE FIRST 10 ROWS TO FAMILIARIZE WITH DATA**

```{r}
head(daily_calories)
```
###### **FINDING OUT BASIC INFORMATION ABOUT THE DATA**

###### * **Name of the dataset, Number of rows & columns, Data types**

```{r}
library (skimr)
skim_without_charts (daily_calories)
```


###### * **Column Names**

```{r}
colnames(daily_calories)
```
###### **CHECKING FOR NULL/MISSING AND DUBLICATE VALUES IN THE DATA**

```{r}
sum(is.na(daily_calories))
sum(duplicated(daily_calories))
```
###### **COUNTING UNIQUE IDs**

```{r}
library(dplyr)
daily_calories %>%
 summarize(unique_Ids = n_distinct(Id))
```
###### **Overall observations**
###### 1. There aren't Null or missing or duplicate values
###### 2. Data has 3 columns and 940 rows
###### 3. ActivityDay is wrongly classified as character datatype and has to be converted to datetime64 datatype.
###### 4. There are 33 unique IDs, similar number with the daily_activity data frame

#### **III. Daily Intensities**
###### **PREVIEWING THE FIRST 10 ROWS TO FAMILIARIZE WITH DATA**

```{r}
head(daily_intensities)
```

###### **FINDING OUT BASIC INFORMATION ABOUT THE DATA**

###### * **Name of the dataset, Number of rows & columns, Data types**

```{r}
library (skimr)
skim_without_charts (daily_intensities)
```
###### * **Column Names**

```{r}
colnames(daily_intensities)
```
###### **CHECKING FOR NULL/MISSING AND DUBLICATE VALUES IN THE DATA**

```{r}
sum(is.na(daily_intensities))
sum(duplicated(daily_intensities))
```
###### **COUNTING UNIQUE IDs**

```{r}
library(dplyr)
daily_intensities %>%
 summarize(unique_Ids = n_distinct(Id))
```
###### **Overall observations**
###### 1. There aren't Null or missing or duplicate values
###### 2. Data has 10 columns and 940 rows
###### 3. ActivityDay is wrongly classified as character datatype and has to be converted to datetime64 datatype.
###### 4. There are 33 unique IDs, similar number with the daily_activity and daily_calories data frames

#### **IV. Daily Sleep**
###### **PREVIEWING THE FIRST 10 ROWS TO FAMILIARIZE WITH DATA**

```{r}
head(daily_sleep)
```

###### **FINDING OUT BASIC INFORMATION ABOUT THE DATA**

###### * **Name of the dataset, Number of rows & columns, Data types**

```{r}
library (skimr)
skim_without_charts (daily_sleep)
```
###### * **Column Names**

```{r}
colnames(daily_sleep)
```
###### **CHECKING FOR NULL/MISSING AND DUBLICATE VALUES IN THE DATA**

```{r}
sum(is.na(daily_sleep))
sum(duplicated(daily_sleep))
```
###### **COUNTING UNIQUE IDs**

```{r}
library(dplyr)
daily_sleep %>%
 summarize(unique_Ids = n_distinct(Id))
```
###### **Overall observations**
###### 1. There aren't Null or missing values, but there are 3 dublicate values
###### 2. Data has 5 columns and 413 rows
###### 3. SleepDate is wrongly classified as character datatype and has to be converted to datetime64 datatype.
###### 4. There are 24 unique IDs, less than then 33 of the previous data frames

#### **V. Weight Info**
###### **PREVIEWING THE FIRST 10 ROWS TO FAMILIARIZE WITH DATA**

```{r}
head(weight_info)
```

###### **FINDING OUT BASIC INFORMATION ABOUT THE DATA**

###### * **Name of the dataset, Number of rows & columns, Data types**

```{r}
library (skimr)
skim_without_charts (weight_info)
```
###### * **Column Names**

```{r}
colnames(weight_info)
```
###### **CHECKING FOR NULL/MISSING AND DUBLICATE VALUES IN THE DATA**

```{r}
sum(is.na(weight_info))
sum(duplicated(weight_info))
```
###### **COUNTING UNIQUE IDs**

```{r}
library(dplyr)
weight_info %>%
 summarize(unique_Ids = n_distinct(Id))
```
###### **Overall observations**
###### 1. There are 65 Null or missing values
###### 2. Data has 8 columns and 67 rows
###### 3. Date is wrongly classified as character datatype and has to be converted to datetime64 datatype.
###### 4. IsManualReport is wrongly classified as character datatype and has to be converted to logical datatype.
###### 5. There are 8 only unique IDs, less than then 33 of the previous data frames

##### **3.5 DATA MANIPULATION & TRANSFORMATION**
#### **I. Daily Activity**

###### **CONVERTING 'ActivityDate' TO DATATIME64 DTYPE**
```{r}
library(lubridate)
daily_activity$ActivityDate <- mdy(daily_activity$ActivityDate)
head(daily_activity$ActivityDate)
```
###### **CREATING NEW COLUMN BY SEPARATING THE 'ActivityDate' INTO 'DayOfTheWeek' FOR FURTHER ANALYSIS**
```{r}
library(dplyr)
daily_activity$DayOfTheWeek <- weekdays(daily_activity$ActivityDate)
```

###### **REARRANGING THE COLUMNS**
```{r}
daily_activity <- daily_activity [, c("Id", "ActivityDate", "DayOfTheWeek", "TotalSteps", "TotalDistance", "TrackerDistance", "LoggedActivitiesDistance", "VeryActiveDistance", "ModeratelyActiveDistance", "LightActiveDistance", "SedentaryActiveDistance", "VeryActiveMinutes", "FairlyActiveMinutes", "LightlyActiveMinutes", "SedentaryMinutes", "Calories")]
head(daily_activity)
```

###### **RENAMING 'ActivityDate' TO 'Date'**
```{r}
daily_activity <- rename(daily_activity, Date=ActivityDate)
```
###### **CREATING NEW COLUMN 'TotalMinutes' BEING THE SUM OF TOTAL TIME LOGGED**

```{r}
daily_activity <- mutate(daily_activity, TotalMinutes = VeryActiveMinutes + FairlyActiveMinutes + LightlyActiveMinutes + SedentaryMinutes) 
head(daily_activity$TotalMinutes)
```
###### **CREATING NEW COLUMN BY CONVERTING 'TotalMinutes' TO 'NumberOfHours'**

```{r}
daily_activity <- mutate(daily_activity, NumberOfHours = TotalMinutes/60) 
head(daily_activity$NumberOfHours)
```
###### **FINALIZING THE COLUMNS' ORDER**
```{r}
daily_activity <- daily_activity [, c("Id", "Date", "DayOfTheWeek", "TotalSteps", "TotalDistance", "NumberOfHours", "TrackerDistance", "LoggedActivitiesDistance", "VeryActiveDistance", "ModeratelyActiveDistance", "LightActiveDistance", "SedentaryActiveDistance", "TotalMinutes", "VeryActiveMinutes", "FairlyActiveMinutes", "LightlyActiveMinutes", "SedentaryMinutes", "Calories")]
head(daily_activity)
```

#### **II. Daily Calories**

###### **CONVERTING 'ActivityDay' TO DATETIME64 DTYPE**
```{r}
library(lubridate)
daily_calories$ActivityDay <- mdy(daily_calories$ActivityDay)
head(daily_calories$ActivityDay)
```
#### **III. Daily Intensities**

###### **CONVERTING 'ActivityDay' TO DATETIME64 DTYPE**
```{r}
library(lubridate)
daily_intensities$ActivityDay <- mdy(daily_intensities$ActivityDay)
head(daily_intensities$ActivityDay)
```
#### **IV. Daily Sleep**

###### **CONVERTING 'SleepDay' TO DATETIME64 DTYPE**
```{r}
daily_sleep$Sleepday <- as.Date(daily_sleep$SleepDay,"%m/%d/%y")
str(daily_sleep)
```

###### **REMOVING DUBLICATES**
```{r}
daily_sleep <- daily_sleep[!duplicated(daily_sleep),] 
```

###### **RECHECKING FOR DUBLICATES**
```{r}
sum(duplicated(daily_sleep))
```
#### **V. Weight Info**

###### **CONVERTING 'Date' TO DATETIME64 DTYPE**
```{r}
weight_info$Date <- mdy_hms(weight_info$Date)
```

###### **CONVERTING 'IsManualReport' TO LOGICAL DTYPE**
```{r}
weight_info$IsManualReport <- as.logical(weight_info$IsManualReport)
str(weight_info)
```
###### **REMOVING THE 'Fat' COLUMN CAUSE 65 OUT OF 67 VALUES ARE MISSING**
```{r}
weight_info <- select(weight_info, -"Fat")
```

### **STEP 4: ANALYZE**

#### **FOCUSING ON DAILY ACTIVITY & DAILY SLEEP**
##### **Both data frames have the same ‘Id’ field, so they can be merged.**

##### **4.1 UNDERSTANDING SOME SUMMARY STATISTICS**

```{r distinct users}
n_distinct(daily_activity$Id)
n_distinct(daily_sleep$Id)
```

##### **4.2 NUMBER OF OBSERVATIONS IN EACH DATA FRAME**

```{r observations}
nrow(daily_activity)
nrow(daily_sleep)
```

###### **4.3 QUICK SUMMARY STATISTICS ABOUT EACH DATA FRAME**

#### **I. Daily Activity**

```{r}
daily_activity %>%
  select(TotalSteps,
         TotalDistance,
         SedentaryMinutes,
         TotalMinutes,
         Calories) %>%
  summary()
```

#### **II. Daily Sleep**
```{r}
daily_sleep %>%  
  select(TotalSleepRecords,
  TotalMinutesAsleep,
  TotalTimeInBed) %>%
  summary()
```

#### **III. Weight Info**
```{r}
weight_info %>%  
  select(WeightKg,
  BMI) %>%
  summary()
```

#### **4.4 INTERPRETING STATISTICAL FINDINGS**

###### **1. On average, users logged 7,638 steps or 5.5km which is not adequate. As recommended by CDC, an adult female has to aim at least 10,000 steps or 8km per day to benefit from general health, weight loss and fitness improvement. [source: Medical News Today Article](https://www.medicalnewstoday.com/articles/how-many-steps-should-you-take-a-day)**
###### **2. Sedentary users are the majority logging on average 991 minutes or 16.5 hours making up 81% of total average minutes.**
###### **3. Noting that average calories burned is 2,304 calories equivalent to 0.65 pound. Could not interpret into detail as calories burned depend on several factors such as the age, weight, daily tasks, exercise, hormones and daily calorie intake. [source: Health Line Article](https://www.healthline.com/health/fitness-exercise/how-many-calories-do-i-burn-a-day)**

### **STEP 5: SHARE**


#### **DATA VISUALIZATION & FINDINGS**

```{r}
install.packages("ggplot2")
library("ggplot2")
```
##### **5.1 FREQUENCY OF USAGE ACROSS THE WEEK**

```{r}
library("ggplot2")
ggplot(data=daily_activity) + geom_bar(mapping=aes(x=DayOfTheWeek,fill=DayOfTheWeek))+
  labs(title="No. of times users logged in app across the week")
```

###### **In this bar chart, we are looking at the frequency of FitBit app usage in terms of days of the week.**

###### **1. We discovered that users prefer to track their activity on the app during midweek from Tuesday to Thursday.**
###### **2. There is a constant drop on frequency from Friday to Monday.**

##### **5.2 CALORIES BURNED FOR EVERY STEP TAKEN**

```{r}
library("ggplot2")
ggplot(data=daily_activity, aes(x=TotalSteps, y = Calories))+ geom_point() + stat_smooth(method=lm)+
   labs(title="Calories burned for every step taken")
```

###### **In the scatter plot above, we can see that:**

###### **1. There is a positive correlation between calories burned and the number of steps.**
###### **2. Intensity of calories burned increases when users are at the range of > 0 to 15,000 steps with calories burn rate cooling down from 15,000 steps onwards.**

###### **Noted a few outliers:**
###### * **1 observation of > 35,000 steps with < 3,000 calories burned.**
###### * **Zero steps with zero to 2,700 calories burned.**
###### **Deduced that outliers could be due to natural variation of data, change in user’s usage or errors in data collection (ie. miscalculations, data contamination or human error).**

##### **5.3 CALORIES BURNED FOR EVERY HOUR LOGGED**

```{r}
library("ggplot2")
ggplot(data=daily_activity, aes(x=NumberOfHours, y = Calories))+ geom_point() + stat_smooth(method=lm)+
   labs(title="Calories burned for every hour logged")+
  annotate("pointrange", x=17.6, y=2250, ymin=0, ymax=5000, colour="red", size=0.5)+
   annotate("text", x=17.6, y = 5200, label="median sedentary", fontface="bold", color="red")
 
```

###### **In the scatter plot above, we can see that:**

###### **1. There is a weak positive correlation whereby the increase of hours logged that cannot translate to more calories being burned. That is largely due to the average sedentary hours (red line) plotted at the 17.6 hours range.** 

###### **Noted a few outliers:**
###### * **The same zero value outliers**
###### * **An unusual dot at the 24 hours with zero calorie burned which may be due to the same reasons as above.**


##### **5.4 SEDENTARY MINUTES FOR EVERY STEP TAKEN**


```{r}
ggplot(data=daily_activity, aes(x=TotalSteps, y = SedentaryMinutes))+ geom_point() + stat_smooth(method=lm)+
  labs(title="Sedentary minutes for every step taken")
```

###### **In the scatter plot above, we can see that:**

###### **1. There is a negative correlation between steps taken in a day and sedentary minutes.**
###### **2. Intensity of sedentary minutes increases when users are at the range of > 5,000 to 15,000 steps with sedentary minutes rate cooling down from 15,000 steps onwards.**

###### **Noted a few outliers:**
###### * **3 observations of > 25,000 steps with > 750 sedentary minutes.**
###### **Deduced that outliers could be due to natural variation of data, change in user’s usage or errors in data collection (ie. miscalculations, data contamination or human error).**


##### **5.5 PERCENTAGE OF ACTIVITY IN MINUTES**


###### * **Summary Data**
```{r}
active_minutes_summary <- daily_activity %>% 
  group_by(Id) %>%
  summarize(avg_very_act_min=mean(VeryActiveMinutes), avg_mod_act_min=mean(FairlyActiveMinutes), avg_light_act_min=mean(LightlyActiveMinutes), avg_sed_min=mean(SedentaryMinutes))
print(active_minutes_summary)
```

###### * **Total number of activity in minutes**

```{r}
minutes <- c("ID", "Very Active Minutes", "Fairly Active Minutes", "Lightly Active Minutes", "Sedentary Minutes")
total_min <- colSums(active_minutes_summary)
total_number_per_minutes <- data_frame(minutes, round(total_min, digit=2))
updated_total_number_per_minutes <- slice(total_number_per_minutes, -c(1))
print(total_number_per_minutes)
```

###### * **Percentage of user activity in minutes**

```{r}
user_activities_intensity <- slice(updated_total_number_per_minutes, -c(5:8))
pct_total_number_per_minutes <- user_activities_intensity %>%
  mutate(pct = scales::percent((user_activities_intensity$`round(total_min, digit = 2)`)/sum(user_activities_intensity$`round(total_min, digit = 2)`)))
print(pct_total_number_per_minutes)
```

```{r}
ggplot(pct_total_number_per_minutes, aes(x='', y=pct, fill=minutes))+
  geom_bar(stat = "identity", width=1)+
  coord_polar("y", start=0)+
  theme_void()+
  geom_text(aes(label = pct), color="white",
            position = position_stack(vjust = 0.5))+
  labs(title="Percentage of Activity in Minutes")
```

###### **As seen from the pie chart:**
###### **Sedentary minutes takes the biggest slice at 81.3%.**
###### **This indicates that users are using the FitBit app to log daily activities such as daily commute, inactive movements (moving from one spot to another) or running errands.**
###### **App is rarely being used to track fitness (ie. running) as per the minor percentage of fairly active activity (1.08%) and very active activity (1.66%). This is highly discouraging as FitBit app was developed to encourage fitness.**

#### **We could position these findings, as a way to induce the users walking more in terms of exercising, than logging their sedentary daily activities.**



##### **5.6 RELATIONSHIP BETWEEN MINUTES ASLEEP AND TIME IN BED**

```{r}
ggplot(data=daily_sleep, aes(x=TotalMinutesAsleep, y=TotalTimeInBed)) + geom_point()
```

###### **As seen from the scatter plot above:**

###### **There is a positive almost completely linear correlation.** 
###### **Although, there are some SIGNIFICANT outliers.**
###### * **There are data points that spend a lot of time in bed, but don't actually sleep, and then a small batch that sleeps and spends time in bed extremely much.**


##### **5.7 MERGING DAILY SLEEP AND DAILY ACTIVITY DATASETS USING OUTER JOIN**

###### **We will use 'outer_join' in order to include all the participant Ids from the two datasets.**

```{r}
combined_data <- merge(x= daily_sleep, y = daily_activity, by="Id",all = TRUE)
head(combined_data)
```


```{r}
n_distinct(combined_data$Id)
```
##### **5.8 RELATIONSHIP BETWEEN SEDENTARY TIME AND TOTAL TIME IN BED**

```{r}
sedentary.lm <- lm(SedentaryMinutes ~ TotalTimeInBed, data = combined_data)
print(sedentary.lm)
```
###### **Correlation Coefficient**

```{r}
cor.test(combined_data$TotalTimeInBed,combined_data$SedentaryMinutes, method = "pearson")
```
###### **It looks like these two things are not related much at all. As time in bed goes up, sedentary minutes actually go down, but not to a statistically significant degree.**


#### **5.9 RELATIONSHIP BETWEEN TOTAL STEPS AND DAILY SLEEP**

```{r}
activity.lm <- lm(TotalSteps ~ TotalMinutesAsleep, data = combined_data)
print(activity.lm)
```

###### **Correlation Coefficient**

```{r}
cor.test(combined_data$TotalMinutesAsleep,combined_data$TotalSteps, method = "pearson")
```
###### **It looks like these two things are not related much at all. As sleeping time goes up, the total steps go down, but not to a statistically significant degree.**



### **STEP 6: ACT**


#### **DELIVERING INSIGHTS & PROVIDING RECOMMENDATIONS BASED ON ANALYSIS**


##### **REVISITING OUR BUSINESS QUESTIONS AND SHARING OUR BUSINESS RECOMMENDATIONS**

###### * What are the trends in smart device usage?
###### * How could these trends apply to Bellabeat customers?
###### * How could these trends help influence Bellabeat marketing strategy?

###### Both companies develop products focused on providing women with their health, habits and fitness data and encouraging them to understand their current habits and make healthy decisions. These common trends surrounding health and fitness can very well be applied to Bellabeat customers.

##### **TRENDS & RECOMMENDATIONS**

###### **INSIGHT #1:** Majority of users (81.6%) are using the FitBit app to track sedentary activities and not using it for tracking their health habits.
###### Recommendations: 
###### * Encourage users by educating and equipping them with knowledge about fitness benefits.
###### * Suggest different types of guided workouts, eg. simple 10 minutes exercise on weekdays and a more intense exercise on weekends.
###### * Provide users with the potential to create their personal workout plan, based on personal goals and preferences on which body parts they need to focus
###### * Provide them with their training statistics (duration, training focus), progress information (weekly/monthly/yearly), calories intake and burnt rate on the Bellabeat app.
###### * Create ranking challenges where users can participate and share their success on Bellabeat app or on social media.


###### **INSIGHT #2:** Users prefer to track their activities during weekdays as compared to weekends - perhaps because they spend more time outside on weekdays and stay in on weekends.
###### Recommendations:
###### * On weekdays, encourage users to share their metrics with friends on social media to drive an increase in user generated content.
###### * On weekends, Bellabeat app can also prompt notification to encourage users to exercise.
###### * Running-routes recommendations, based on user's personal data (location, workplace/house, gps tracker, most walkable places, etc)

###### **INSIGHT #3:** Although sleep is automatically tracked and logged, a slight drop-off in users is noted and a significant drop off in frequency days logged is observed. Users may have not been wearing the smart device due to discomfort.
###### Recommendation:
###### * Highlight the importance of tracking rest and inform the target market of the product’s features that allow for a comfort feel.


###### **INSIGHT #4:** No data for hydration is present in the Fitbit data set.
###### Recommendation:
###### * Leverage this competitive advantage to differentiate the Bellabeat brand from other smart device companies.
###### * Highlight how the addition of the Spring water bottle completes their product ecosystem and helps users better achieve their health and fitness goals.







